{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Amy Weng\n",
    "\n",
    "Word2Vec Continuous Skip-Gram Model Word Embedding and Visualization\n",
    "\n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from words import remove_stopwords\n",
    "from gensim.scripts import word2vec2tensor\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Phrases\n",
    "\n",
    "def embed(df,title):\n",
    "    data = df.text.values.tolist()\n",
    "    # preprocess and remove stopwords\n",
    "    data = remove_stopwords(data)\n",
    "    # Train a bigram detector.\n",
    "    bigram_transformer = Phrases(data)\n",
    "    # Train a skip-gram model with the bigram detector \n",
    "    model = Word2Vec(bigram_transformer[data], min_count=5,sg=1)\n",
    "    # save model so we can reload later  \n",
    "    model.save('/home/rapiduser/Materials/embeddings/'+title+'.model')\n",
    "    # save model in a format that can be converted to tensor TSV \n",
    "    model.wv.save_word2vec_format('/home/rapiduser/Materials/embeddings/tensor/'+title+'.model')\n",
    "    return(model)\n",
    "\n",
    "def similar(model,word,num):\n",
    "    if word in model.wv.key_to_index.keys():\n",
    "        words = []\n",
    "        first = 0\n",
    "        score = 0\n",
    "        for w, s in model.wv.most_similar(word,topn=num):\n",
    "            if first == 0:\n",
    "                score = s\n",
    "                first += 1\n",
    "            words.append(w)\n",
    "        #     words.append((w,s))\n",
    "        # print(word + ': ',words)\n",
    "        print(word + ': '+' '.join(words))\n",
    "        print('The most similar word has cosine distance '+str(score))\n",
    "\n",
    "def comparePair(model,word1,word2):\n",
    "    if word1 and word2 in model.wv.key_to_index.keys():\n",
    "        print('Cosine similarity between ' + word1 + ' and ' + word2 + ': ',model.wv.similarity(word1, word2))\n",
    "\n",
    "def tensor(f_name):\n",
    "    word2vec2tensor.word2vec2tensor(\n",
    "        '/home/rapiduser/Materials/embeddings/tensor/'+f_name+'.model',\n",
    "        '/home/rapiduser/ECBC-21-22/Text_Files/Embeddings TSV/'+f_name,\n",
    "        binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCSV = '/home/rapiduser/Materials/topic model/publica/eic_monopoly.csv'\n",
    "\n",
    "readFile = pd.read_csv(myCSV)\n",
    "\n",
    "# read text information into a dataframe\n",
    "publica_eic_monopoly = embed(readFile,'publica_eic_monopoly')\n",
    "tensor('publica_eic_monopoly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publica_eic_monopoly = Word2Vec.load('/home/rapiduser/Materials/embeddings/publica_eic_monopoly.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCSV = '/home/rapiduser/Materials/topic model/publica/eic.csv'\n",
    "\n",
    "readFile = pd.read_csv(myCSV)\n",
    "\n",
    "# read text information into a dataframe\n",
    "publica_eic = embed(readFile,'publica_eic')\n",
    "tensor('publica_eic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar(publica_eic,'corruption',15)\n",
    "print('\\n')\n",
    "similar(publica_eic,'monopoly',15)\n",
    "print('\\n')\n",
    "similar(publica_eic,'monopolies',15)\n",
    "print('\\n')\n",
    "similar(publica_eic,'body_politic',15)\n",
    "print('\\n')\n",
    "similar(publica_eic,'odious',15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monopolies: laws_land freedom_trade retrained restrained equal_right lawful lives_liberties limitations exercie authorities\n",
      "The most similar word has cosine distance 0.9826760292053223\n",
      "monopoly: joint_stocks monopolies freedom_trade privilege retrained regulated_company majeties_subjects conideration particulars pretence\n",
      "The most similar word has cosine distance 0.9539591670036316\n",
      "monopolise: carved present_constitution ingroed befalls tion establishment_new moreover impounding avenge majesties_revenue\n",
      "The most similar word has cosine distance 0.9954888224601746\n",
      "monopolising: enriched increase_navigation rates_exchange encourages_navigation inland remote_parts riches_strength increases increase_seamen luxurious_prodigal\n",
      "The most similar word has cosine distance 0.9905856847763062\n",
      "monopolists: careful_avoid queez superstructure expend perspicuous whiteness proportioned rightly_understood lessening exhauting\n",
      "The most similar word has cosine distance 0.995648205280304\n",
      "monopolizers: dearet considers lil artians dearest highest_degree intrigue adventures_returns ilands vat_extent\n",
      "The most similar word has cosine distance 0.9949625730514526\n",
      "monopolised: managing confining forces_forts majeties_revenue admiion admission imprudent impaired enlargement_trade unneceary\n",
      "The most similar word has cosine distance 0.9932711720466614\n",
      "monoopolies: total_villa diowns aliquas spelthorn devises_lands insanity desuetude sauk banister bridge_tower\n",
      "The most similar word has cosine distance 0.38581404089927673\n",
      "monopolits: raw_ilks consuming double_tax prodigal_expense monopolists cumber deduction conumptions pony shooing\n",
      "The most similar word has cosine distance 0.9949973821640015\n",
      "monopolers: occained scaly hetheral urbin blaier dictaque fideli_coniliario propects armigerum bourks\n",
      "The most similar word has cosine distance 0.391268253326416\n",
      "monopoliing: endeavours_ued albeit michievous nursery mistrust turk ceases lightly sew highet_degree\n",
      "The most similar word has cosine distance 0.9879429340362549\n"
     ]
    }
   ],
   "source": [
    "from words import monopoly\n",
    "m = monopoly.split('|')\n",
    "for w in m:\n",
    "    similar(publica_eic_monopoly,w,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparePair(publica_eic_monopoly,'body_politic','monopoly')\n",
    "comparePair(publica_eic_monopoly,'body_politick','monopoly')\n",
    "comparePair(publica_eic_monopoly,'body_politic','monopolies')\n",
    "comparePair(publica_eic_monopoly,'body_politick','monopolies')\n",
    "comparePair(publica_eic_monopoly,'public_utility','monopolies')\n",
    "comparePair(publica_eic_monopoly,'public_affairs','monopolies')\n",
    "comparePair(publica_eic_monopoly,'wicked','monopoly')\n",
    "comparePair(publica_eic_monopoly,'illegal','monopoly')\n",
    "comparePair(publica_eic_monopoly,'engrossing','monopoly')\n",
    "comparePair(publica_eic_monopoly,'odious','monopoly')\n",
    "comparePair(publica_eic_monopoly,'evil','monopoly')\n",
    "comparePair(publica_eic_monopoly,'repugnant','monopoly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparePair(publica_eic_monopoly,'arbitrary','corruption')\n",
    "comparePair(publica_eic_monopoly,'popery','corruption')\n",
    "comparePair(publica_eic_monopoly,'papist','corruption')\n",
    "comparePair(publica_eic_monopoly,'monopoly','corruption')\n",
    "comparePair(publica_eic_monopoly,'bribery','corruption')\n",
    "comparePair(publica_eic_monopoly,'remedies','corruption')\n",
    "comparePair(publica_eic_monopoly,'remedy','corruption')\n",
    "comparePair(publica_eic_monopoly,'monopoly_evils','corruption')\n",
    "comparePair(publica_eic_monopoly,'body_politick','corruption')\n",
    "comparePair(publica_eic_monopoly,'body_politic','corruption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar(publica_eic_monopoly,'circulation',10)\n",
    "similar(publica_eic_monopoly,'disease',10)\n",
    "similar(publica_eic_monopoly,'remedy',10)\n",
    "similar(publica_eic_monopoly,'remedies',10)\n",
    "similar(publica_eic_monopoly,'wasting',10)\n",
    "similar(publica_eic_monopoly,'waste',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption = 'consumption|consume|consuming|consumed|conume|conumption|conuming|conumed'\n",
    "c = consumption.split('|')\n",
    "for w in c:\n",
    "    similar(publica_eic_monopoly,w,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corruption = 'corruption|corrupt|corrupted|corruptions|corrupting'\n",
    "corrupt = corruption.split('|')\n",
    "for w in corrupt:\n",
    "    similar(publica_eic_monopoly,w,10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
