{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22dcf014",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00aa4ba",
   "metadata": {},
   "source": [
    "By Amy Weng\n",
    "\n",
    "Adapted from Heidi Smith's File (Topic_Model_Attempt_1.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b624c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.corpora as corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc8c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/rapiduser/Materials/'\n",
    "results = '/home/rapiduser/Materials/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "da8ce956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords/preprocess\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['thus', 'thereof', 'thence', 'thee', 'therein', \n",
    "                    'wherein', 'whereby', 'whereas', 'also', 'us', 'upon', \n",
    "                    'would', 'within', 'indeed', 'become', 'viz', 'per', 'anno', \n",
    "                    'whilst', 'thoe', 'ome', 'uch', 'said', 'shall', 'hath',\n",
    "                    'may','made','much','one','mr','how','like','full','one',\n",
    "                    'two','three','four','five','day','say','thou','make','men','man',\n",
    "                    'done','do','have','well','know','heard','hear',\n",
    "                    'saying','come','never','time','think','came','till','might',\n",
    "                    'could','begin','began','took','went','last','matter','seeing',\n",
    "                    'go','many','few','see','take','found','without','little','long',\n",
    "                    'put','brought','bring','another','th','aforesaid','old','son',\n",
    "                    'tell','em','yet','cae','mot','doe','aloe','every','elf',\n",
    "                    'himelf','thy','de','ch','com','says','part','through','let',\n",
    "                    'must','sir','tho','away','part','unto','printed','doth',\n",
    "                    'iq','esq','firt','et','among','everal','ver','called','lt',\n",
    "                    'every','even','becaue','ibid','de','lib','ch','com','often',\n",
    "                    'againt','second','dr','though','goes','non','equire',\n",
    "                    'page','told','hold','sr','ditto','elf','therefore','de',\n",
    "                    'ps','six','ent','mr','inits'])\n",
    "        \n",
    "def remove_stopwords(data):\n",
    "    return [[word for word in simple_preprocess(str(doc))\n",
    "            if word not in stop_words] for doc in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9ec9bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexicons\n",
    "publica = \"adventurers|aid|ally|ambaador|ambassador|amboyna|amsterdam|argier|army|austerity|authority|bank|banks|bantam|bill|bills|body politic|bond|britain|bullion|bullionist|charles|china|chocolate|christiandom|cinnamon|civil war|civilian|coffee|coin|commerce|commercial|commodities|commodity|commonwealth|company|constitution|consumables|consume|consumer|consuming|consumption|controversies|controversy|copper|corn|corporate|corporation|country|credit|creditor|crisis|crisis|currency|debt|debtor|decoctor|decree|decrees|defendant|dutch|duties|east india company|east indies|east-india company|east-india-company|eat-india company|economic|economy|empire|employment|enemy|england|england|estate|exchange|exchequer|exportation|extortion|factory|fih|fihing|fiscal|fish|fishery|fishing|foreign|free trade|germany|ginger|gold|goods|government|governor|herring|hillings|holy roman empire|house of commons|house of lords|importation|income|india|india|indian|indies|indonesia|industry|interest|interest rate|interest rates|interet|ireland|james|joint-stock|king|kingdom|kingdom|land|law|laws|london|lord|low countries|majesty|mary|massacre|mercantile|merchandise|merchant|merchants|military|money|monies|monopolie|monopolies|monopolion|monopolist|monopolium|monopolization|monopolize|monopolizer|monopolizes|monopoly|monopolye|monopolyes|mughal|nation|national|navy|netherlands|netherlands|oppression|parliament|parliament|pay|pence|pences|pepper|pirate|pirates|plaintiff|pleads|politic|political|pound|pounds|power|price|prices|prince|privileges|profitable|property|protection|provincial|public|publicke|queen|quote|restoration|revenue|revolution|ruler|scandal|scandalous|scotland|shilling|shillings|ships|siam|silk|silver|spanish|spending|spices|spices|sterling|stock|strength|stuart|subject|substance|taxation|taxes|tea|textiles|tobacco|tories|tory|trade|traffic|traffique|treasure|treatise|treatises|tunis|turkish|unprofitable|usurer|usury|war|whig|whigs|william|work|interlopers|interloper|planters|manufacture|manufacturing|courts|court|hollanders|tradesmen|creditors|factories|princes|companies|african|africa|proecutors|seamen|proecutor|spain|emperor|shipping|clothier|clothiers|manufacturers|conumption|conume|moneys|proclamation|abroad|treaty|treaties|courten|nets|wood|negroes|bavaria|manufactures|petitioners|petitioner|bankrupts|gunpowder|governors|bankrupt|salt|plantations|coined|mint|minted|license|licensing|licenser|supply|admiral|calico|calicoes|revenues|mines\"\n",
    "religio = 'abnegatio|abraham|absolution|abundance|adam|adultery|almighty|altar|anathema|annihilate|anoint|anointing|antichrist|apocalypse|apostle|archangel|armageddon|arrogant|ascension|atone|atonement|avarice|baptism|bathsheba|bible|biblical|bishop|blasphemy|bless|blessed|blessing|born-again|bread|brother|caesar|calvinist|candles|canon|catholic|cessans|chalice|chapel|chaplain|charity|cheat|cheating|cherub|christ|christian|christianity|church|cleansing|coming|commandments|communion|condemn|condemnation|confess|confession|confront|confronts|congregation|conscience|consecration|contempt|contrite|contrition|conviction|covenant|create|creation|creed|cross|crown|cuckold|curse|damask|damn|damnation|damned|david|day|deacon|death|deceit|deceitful|deceive|deceive|defile|defiled|delilah|demon|depravity|desire|desires|destruction|deuteronomy|devil|disciple|disciples|disobey|divine|doctrine|ecumenical|endure|entice|enticed|epistle|eternal|evangelical|evangelicalism|eve|evil|excommunication|exile|exodus|faith|false|falsehood|fellowship|forgive|forgiveness|fortune|fraud|freedom|fundamental|generation|genesis|gentile|gluttony|god|godly|gospel|grace|greed|green|grievance|guilt|guilty|hallelujah|heaven|hebrew|hebrews|hell|heresy|heresy|holiness|holy|human|hypocrisy|incest|indulgence|indulgent|integrity|isaiah|james|jehovah|jesus|job|john|john|john|judaism|judgment|justification|justify|knowledge|lechery|leviticus|lie|lies|liturgy|lord|lucifer|lucrum|luke|lust|lustful|lustfully|luxury|manifestation|mark|mass|matthew|mendicancy|messiah|ministry|mission|missionary|modesty|moon|moral|moses|natural|nature|numbers|obedience|obey|offering|offerings|ordained|ordinance|ordinate|ordination|orthodox|pagan|paganism|pagans|palace|papacy|papist|parable|parables|parish|parishioner|passover|pastor|penance|perfect|persecution|peter|pleasant|pope|popery|pray|prayer|predestination|pride|priesthood|prodigal|prodigality|prophecy|prophet|protestant|proverb|proverbs|providence|psalm|psalms|purgatory|radiance|rapture|reap|reconcile|reconciliation|redeem|redeemed|redemption|reform|reformed|reincarnate|reincarnation|reject|rejected|rejoice|rejoiced|religion|render|repent|resurrect|resurrection|revelation|rich|righteous|righteousness|ritual|roman|rome|root|sabbath|sacrament|sacred|sacrifice|sacrifices|saint|salvation|samaritan|samson|samuel|sanctified|sanctify|sanctuary|satan|satanic|satanism|save|saved|saved|savior|scripture|scriptures|second|secure|security|self-denial|sermon|simony|sin|sin|sinful|sister|slave|slaves|sloth|soul|sown|spirit|splendor|splendor|station|stations|sumptuary|sun|supper|tempt|ten|tenant|tenants|testament|theft|thrive|timothy|tongues|tower|transgression|tribulation|trinity|trust|truth|twelve|unfaithful|union|universal|unnatural|vanity|velvet|venial|virgin|vision|vulgate|wealth|whore|wicked|wickedness|wine|wise|witness|word|words|worship|zion|presbyterians|presbyterian|prohibition|anabaptists|prejudicial'\n",
    "medica = 'asthma|asthma|atrophy|bad|bezoar|bile|bleed|bleeding|blood|body|brain|breathing|cancer|canker|circulate|circulation|clots|clotting|cold|constitution|consume|consumption|contamination|corpora|corpus|corrupt|corruptio|corruption|corruptionem|cough|cure|cured|dead|death|decay|decay|deceased|defect|degenerate|degeneration|destroy|diabetes|diagnosis|disease|dissolution|distemper|drinks|dry|dying|enfeeblement|envy|evacuation|exercise|faculties|fatal|fatality|fever|fiber|fog|healthy|heart|hemorrhage|hepatitis|herb|herbs|hot|hysteria|illness|impairment|inanition|insane|jealousy|languish|leech|leeches|liver|lung|malaria|medical|medicine|melancholy|miasma|mind|moist|morbid|mortal|mortality|mouth|nerves|nervous|opiate|opium|perversion|perverto|phlegm|physician|plague|plague|pox|prognosis|putrid|putrid|remedies|remedy|sana|sane|sanguine|sick|sickness|smells|smoke|sores|spirit|spoil|spoiling|stomach|supple|surgeon|surgeons|swelling|tetrid|therapeutic|tuberculosis|ulcer|unhealthy|unwholesome|upset|vein|vein|vessels|vice|vita|vital|vitiare|vitiation|vitium|vomit|waste|wasting|wholesome|wintergreen|zodiac'\n",
    "\n",
    "pub = re.compile(publica)\n",
    "rel = re.compile(religio)\n",
    "med= re.compile(medica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c447a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabetize(lexicon,name):\n",
    "    string = '|'.join(sorted(lexicon.split('|')))\n",
    "    print(name+' = '+'\\''+string+'\\'')\n",
    "\n",
    "alphabetize(medica,'medica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6d623542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(df):\n",
    "    data = df.text.values.tolist()\n",
    "    data = remove_stopwords(data)\n",
    "\n",
    "    id2word = corpora.Dictionary(data)\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in data]\n",
    "    num_topics = 1\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                        id2word=id2word,\n",
    "                                        num_topics=num_topics)\n",
    "    for idx, topic in lda_model.show_topics(formatted=False, num_words= 10):\n",
    "        return ('{}'.format(' '.join([w[0] for w in topic])))\n",
    "\n",
    "def sortByTopics(topics):\n",
    "\n",
    "    p = len(re.findall(pub, topics))/10\n",
    "    r = len(re.findall(rel, topics))/10\n",
    "    m = len(re.findall(med, topics))/10\n",
    "\n",
    "    maxRatio = max(p,r,m)\n",
    "\n",
    "    if maxRatio==0:\n",
    "        return 'altera'  \n",
    "    elif p==maxRatio: \n",
    "        return 'publica'\n",
    "    elif r==maxRatio:\n",
    "        return 'religio'\n",
    "    else:\n",
    "        return 'medica'\n",
    "\n",
    "def save(topics,folder,f_name):\n",
    "    name = f_name.rsplit('.', 1)[0]\n",
    "    txtFile = directory+'topic model/'+folder+'/'+name+'.txt'\n",
    "    w = open(txtFile,'a+')\n",
    "    w.write(topics+'\\n')\n",
    "    w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a65a9112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "Publica:  444\n",
      "Religio:  32\n",
      "Medica:  3\n",
      "Altera:  5\n"
     ]
    }
   ],
   "source": [
    "f_name = 'eic.csv'\n",
    "folder = 'Texts/'\n",
    "myCSV = directory + folder + f_name\n",
    "\n",
    "df_p = pd.DataFrame(columns=('title','author','publisher','date','text'))\n",
    "df_r = pd.DataFrame(columns=('title','author','publisher','date','text'))\n",
    "df_m = pd.DataFrame(columns=('title','author','publisher','date','text'))\n",
    "df_a = pd.DataFrame(columns=('title','author','publisher','date','text'))\n",
    "\n",
    "# Read in csv\n",
    "readFile = pd.read_csv(myCSV)\n",
    "\n",
    "# Iterate over each text (row) in csv\n",
    "for i in range(len(readFile.index)):\n",
    "    \n",
    "    df = readFile[i:(i+1)]\n",
    "    \n",
    "    topics = model(df)\n",
    "    \n",
    "    t = sortByTopics(topics)\n",
    "    \n",
    "    save(topics,t,f_name)\n",
    "\n",
    "    if t=='publica':\n",
    "        df_p = df_p.append(df)\n",
    "    \n",
    "    elif t=='religio':\n",
    "        df_r = df_r.append(df)\n",
    "    \n",
    "    elif t=='medica':\n",
    "        df_m = df_m.append(df)\n",
    "    \n",
    "    else:\n",
    "        df_a = df_a.append(df)\n",
    "\n",
    "    if (i != 0) & (i % 100 == 0):\n",
    "        print(i) \n",
    "    \n",
    "if not df_p.empty:    \n",
    "    df_p.to_csv(directory+'topic model/publica/'+f_name) \n",
    "    print(\"Publica: \",len(df_p))\n",
    "\n",
    "if not df_r.empty:    \n",
    "    df_r.to_csv(directory+'topic model/religio/'+f_name)\n",
    "    print(\"Religio: \",len(df_r))\n",
    "\n",
    "if not df_m.empty:    \n",
    "    df_m.to_csv(directory+'topic model/medica/'+f_name)\n",
    "    print(\"Medica: \",len(df_m))\n",
    "\n",
    "if not df_a.empty:    \n",
    "    df_a.to_csv(directory+'topic model/altera/'+f_name)\n",
    "    print(\"Altera: \",len(df_a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ebdffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine(folder,f_name):\n",
    "    name = f_name.rsplit('.', 1)[0]\n",
    "    txtFile = directory+'topic model/'+folder+'/'+name+'.txt'\n",
    "    w = open(txtFile,'r')\n",
    "    words = []\n",
    "    for line in w.readlines():\n",
    "        line = line.replace('\\n','')\n",
    "        newlist = line.split(' ')\n",
    "        words.extend(newlist)\n",
    "\n",
    "    unique = set()\n",
    "    unique.update(list)\n",
    "\n",
    "    m = ' '.join(medica.split('|'))\n",
    "    r = ' '.join(religio.split('|'))\n",
    "    p = ' '.join(publica.split('|'))\n",
    "    a = []\n",
    "    for word in unique:\n",
    "        if (re.search(word,p)==None) and (re.search(word,r)==None) and (re.search(word,m)==None):\n",
    "            a.append(word)\n",
    "    w.close()\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb00ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim_models\n",
    "# # Visualize the topics\n",
    "# pyLDAvis.enable_notebook()\n",
    "# LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "# pyLDAvis.save_html(LDAvis_prepared, results+'/post-restoration.html')\n",
    "# LDAvis_prepared\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
