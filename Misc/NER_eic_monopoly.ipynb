{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c71dbcb",
   "metadata": {},
   "source": [
    "Author: Amy Weng\n",
    "\n",
    "This file is for running named entity recognition (NER) using spaCy on individual Restoration-era texts that mention BOTH monopoly and East India Company. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f9417b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "import spacy\n",
    "directory = r'C:\\Users\\amycw\\Desktop\\ecbc research'\n",
    "eicFolder = directory + \"\\\\\"+'eic_monopoly_eebo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b6c6d6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the history of england giving a true and impartial account of the most considerable transactions in church and state in peace and war during the reigns of all the kings and queens from the coming of julius caesar into britain with an account of all plots conspiracies insurrections and rebellions likewise a relation of the wonderful prodigies to the year together with a particular description of the rarities in the several counties of england and wales with exact maps of each county by john seller \n",
      "\n",
      "1185040\n"
     ]
    }
   ],
   "source": [
    "# check for files that are bigger than 1000000 \n",
    "for file in os.listdir(eicFolder):\n",
    "    entries = pd.read_csv(eicFolder + \"\\\\\" + file)\n",
    "    num_rows = entries.index\n",
    "    num_texts = len(num_rows)\n",
    "    for i in range(num_texts):\n",
    "        data = entries[i:(i+1)]\n",
    "        text = data.iloc[0].text\n",
    "        title = data.iloc[0].title\n",
    "        if (len(text)>=1000000):\n",
    "            print(title+\"\\n\")\n",
    "            print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "507b3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running named entity recognition using spaCy on eicFolder\n",
    "nerFile = open(r'C:\\Users\\amycw\\Desktop\\ecbc research\\namedEntityRecognition.txt', \"a\")\n",
    "ner = spacy.load('en_core_web_sm')\n",
    "for fileName in os.listdir(eicFolder):\n",
    "    readFile = pd.read_csv(eicFolder + \"\\\\\" + fileName)\n",
    "    for i in range(len(readFile.index)):\n",
    "        data = readFile[i:(i+1)]\n",
    "        text = data.iloc[0].text\n",
    "        entities = ner(text)\n",
    "        for ent in entities.ents:\n",
    "            nerFile.write(ent.text+\" \"+ent.label_+\"\\n\")\n",
    "nerFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "526c4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabetize and sort entities by frequency\n",
    "\n",
    "nerFile = open(r'C:\\Users\\amycw\\Desktop\\ecbc research\\namedEntityRecognition.txt', \"r\")\n",
    "SortedNER = open(r'C:\\Users\\amycw\\Desktop\\ecbc research\\sortedNamedEntityRecognition.txt',\"a\")\n",
    "SortedNER.write(\"format is (<name> <TYPE>, <frequency>)\\n\")\n",
    "uniqueEnts = {} \n",
    "entities = []\n",
    "indices = []\n",
    "entities = nerFile.read().split(\"\\n\")\n",
    "for ent in entities:\n",
    "    if ent not in indices: \n",
    "        uniqueEnts[ent] = 1\n",
    "        indices.append(ent)\n",
    "    else: \n",
    "        uniqueEnts[ent] = uniqueEnts[ent] + 1 \n",
    "alphabetizedEnts = {}\n",
    "for ent in sorted(uniqueEnts): \n",
    "    alphabetizedEnts[ent]=uniqueEnts[ent] \n",
    "for pair in sorted (alphabetizedEnts.items(), key=lambda kv:(kv[1], kv[0]), reverse=True):\n",
    "    SortedNER.write(str(pair)+\"\\n\")\n",
    "SortedNER.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18770509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#break the too big file into two smaller ones \n",
    "\n",
    "breakFile = r'C:\\Users\\amycw\\Desktop\\ecbc research\\eic_monopoly_eebo\\A5_P4_3070.csv'\n",
    "entries= pd.read_csv(breakFile)\n",
    "half = []\n",
    "otherHalf = []\n",
    "count = 0 \n",
    "string = \"\"\n",
    "other = \"\"\n",
    "for i in range(len(entries.index)):\n",
    "    d = entries[i:(i+1)]\n",
    "    text = d.iloc[0].text\n",
    "    words = text.split(\" \")\n",
    "    for w in words: \n",
    "        if (count <= (len(words)/2)):\n",
    "            half.append(w)\n",
    "            count+=1\n",
    "        else:\n",
    "            otherHalf.append(w)\n",
    "for w in half:\n",
    "    string = string + w + \" \"\n",
    "for w in otherHalf: \n",
    "    other = other + w + \" \"\n",
    "\n",
    "df1 = pd.DataFrame([(d.iloc[0].index, d.iloc[0].title,d.iloc[0].author,d.iloc[0].publisher,d.iloc[0].date,string)],\n",
    "           columns=('index', 'title','author','publisher','date','text'))\n",
    "df2 = pd.DataFrame([(d.iloc[0].index, d.iloc[0].title,d.iloc[0].author,d.iloc[0].publisher,d.iloc[0].date,other)],\n",
    "           columns=('index', 'title','author','publisher','date','text'))\n",
    "df1.to_csv(eicFolder + \"\\\\\" + 'A5_P4_3070_1.csv', index=False)\n",
    "df2.to_csv(eicFolder + \"\\\\\" + 'A5_P4_3070_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
